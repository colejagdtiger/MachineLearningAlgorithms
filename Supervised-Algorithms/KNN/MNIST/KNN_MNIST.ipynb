{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Assignment_1_Part1_notebook.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYqF-b6dBoXn"
      },
      "source": [
        "Import and setup some auxiliary functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dL4u1UElBoXo"
      },
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import timeit\n",
        "from collections import OrderedDict\n",
        "from pprint import pformat\n",
        "\n",
        "\n",
        "def compute_score(acc, min_thres, max_thres):\n",
        "    if acc <= min_thres:\n",
        "        base_score = 0.0\n",
        "    elif acc >= max_thres:\n",
        "        base_score = 100.0\n",
        "    else:\n",
        "        base_score = float(acc - min_thres) / (max_thres - min_thres) \\\n",
        "                     * 100\n",
        "    return base_score\n",
        "\n",
        "\n",
        "def run(algorithm, x_train, y_train, x_test, y_test, n_classes, device,k):\n",
        "    print('Running...')        \n",
        "    if device != 'cpu' and torch.cuda.is_available():\n",
        "        device = torch.device(\"cuda\")\n",
        "        print('Training on GPU: {}'.format(torch.cuda.get_device_name(0)))\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "        print('Training on CPU')\n",
        "        \n",
        "    start = timeit.default_timer()\n",
        "    np.random.seed(0)\n",
        "    predicted_y_test = algorithm(x_train, y_train, x_test, n_classes, device,k)\n",
        "    np.random.seed()\n",
        "    stop = timeit.default_timer()\n",
        "    run_time = stop - start\n",
        "\n",
        "    correct_predict = (y_test\n",
        "                       == predicted_y_test).astype(np.int32).sum()\n",
        "    incorrect_predict = len(y_test) - correct_predict\n",
        "    accuracy = float(correct_predict) / len(y_test)\n",
        "\n",
        "    print('Correct Predict: {}/{} total \\tAccuracy: {:5f} \\tTime: {:2f} k: {:n}'.format(correct_predict,\n",
        "                                                                                len(y_test), accuracy, run_time, k))\n",
        "    return correct_predict, accuracy, run_time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5_lbZASBoXr"
      },
      "source": [
        "TODO: Implement knn here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yHgmydUBoXr"
      },
      "source": [
        "def knn(x_train, y_train, x_test, n_classes, device,k):\n",
        "    \"\"\"\n",
        "    x_train: 60000 x 784 matrix: each row is a flattened image of an MNIST digit\n",
        "    y_train: 60000 vector: label for x_train\n",
        "    x_test: 1000 x 784 testing images\n",
        "    n_classes: no. of classes in the classification task\n",
        "    device: pytorch device on which to run the code\n",
        "    return: predicted y_test which is a 1000-sized vector\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    create a numpy array of zeros for predictions\n",
        "    dtype is automatically recognized by analysing y_train for classification purpose\n",
        "    \"\"\"\n",
        "    ypred = np.zeros(1000,dtype = y_train.dtype)\n",
        "\n",
        "    \"\"\" \n",
        "    Convert training and test arrays to tensor ; reference = https://pytorch.org/docs/stable/tensors.html\n",
        "    dtypes are set to float as well as the device is automatically recognized\n",
        "    \"\"\"\n",
        "    x_train= torch.tensor(x_train, dtype=torch.float, device=device)\n",
        "    x_test = torch.tensor(x_test, dtype=torch.float, device=device)\n",
        "\n",
        "    \"\"\" \n",
        "    loop over the range of 1000 testing images\n",
        "    \"\"\"\n",
        "    for index in range(x_test.shape[0]):\n",
        "\n",
        "      \"\"\" \n",
        "      find the L2 norm of the training set - test set (here p = 2 means the L2 norm)\n",
        "      After hyper paramenter tuning the best value of k was found to be 1\n",
        "      the p value was found to be 4 which yielded a best accuracy of 97% although slower which yielded in a loss of 2 seconds\n",
        "      the p value = 2 that is the euclidean distance yielded 96.3% in 4.4 at best and on average at 5 seconds.\n",
        "      \"\"\"\n",
        "      distances = torch.norm(x_train-x_test[index],p = 4,dim = 1)\n",
        "\n",
        "      \"\"\"\n",
        "      find the min element and the index it is at ; reference = https://pytorch.org/docs/stable/generated/torch.topk.html\n",
        "      largest is set to false as we want the smallest element and not the largest one\n",
        "      \"\"\"\n",
        "      element,min_index = torch.topk(distances,1,largest = False)\n",
        "  \n",
        "      \"\"\"\n",
        "      find the value of it in the y_train set and assign it to predictions\n",
        "      \"\"\"\n",
        "      ypred[index] = y_train[min_index]\n",
        "      \n",
        "    return ypred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkZ_qUyeBoXt"
      },
      "source": [
        "Main loop. You can only run this after filling the knn function above"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skv5jrRCBoXu",
        "outputId": "b2f6d859-39fa-476f-ae25-a3d79bbba201",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "min_thres = 0.84\n",
        "max_thres = 0.94\n",
        "n_classes = 10\n",
        "# change to cpu to run on CPU\n",
        "device = 'gpu'\n",
        "\n",
        "mnist_train = datasets.MNIST('data', train=True, download=True,\n",
        "                             transform=transforms.Compose([\n",
        "                                 transforms.Normalize((0.1307,), (0.3081,)),\n",
        "                             ])\n",
        "                             )\n",
        "mnist_test = datasets.MNIST('data', train=False, download=True,\n",
        "                             transform=transforms.Compose([\n",
        "                                 transforms.Normalize((0.1307,), (0.3081,)),\n",
        "                             ])\n",
        "                            )\n",
        "result = [OrderedDict(first_name='Robert',last_name='Joseph')]\n",
        "\n",
        "# convert pytorch tensors to numpy arrays\n",
        "(x_train, y_train) = (mnist_train.data.cpu().numpy(), mnist_train.targets.cpu().numpy())\n",
        "(x_valid, y_valid) = (mnist_test.data.cpu().numpy(), mnist_test.targets.cpu().numpy())\n",
        "\n",
        "# flatten 28x28 images into 784 sized vectors\n",
        "x_train = x_train.reshape(x_train.shape[0], -1)\n",
        "x_valid = x_valid.reshape(x_valid.shape[0], -1)\n",
        "\n",
        "# You may want to use a smaller training set to save time when debugging\n",
        "# i.e.: Put something like:\n",
        "#(x_train, y_train) = (x_train[:5000], y_train[:5000])\n",
        "\n",
        "# For this assignment, we only test on the first 1000 samples of the test set\n",
        "(x_valid, y_valid) = (x_valid[:1000], y_valid[:1000])\n",
        "\n",
        "#z = knn(x_train,y_train,x_valid,n_classes,device)\n",
        "#print(z)\n",
        "\n",
        "print(\"Dimension of dataset: \")\n",
        "print(\"Train:\", x_train.shape, y_train.shape, \"\\nTest:\", x_valid.shape, y_valid.shape)\n",
        "\n",
        "\n",
        "(correct_predict, accuracy, run_time) = run(knn, x_train, y_train, x_valid, y_valid, n_classes, device,1)\n",
        "score = compute_score(accuracy, min_thres, max_thres)\n",
        "result = OrderedDict(correct_predict=correct_predict,accuracy=accuracy, score=score,run_time=run_time)\n",
        "\n",
        "with open('result.txt', 'w') as f:\n",
        "    f.writelines(pformat(result, indent=4))\n",
        "\n",
        "print(pformat(result, indent=4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dimension of dataset: \n",
            "Train: (60000, 784) (60000,) \n",
            "Test: (1000, 784) (1000,)\n",
            "Running...\n",
            "Training on GPU: Tesla T4\n",
            "Correct Predict: 967/1000 total \tAccuracy: 0.967000 \tTime: 3.430022 k: 1\n",
            "OrderedDict([   ('correct_predict', 967),\n",
            "                ('accuracy', 0.967),\n",
            "                ('score', 100.0),\n",
            "                ('run_time', 3.4300224259999936)])\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}